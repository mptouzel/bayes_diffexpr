\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Benichou2011,Georgiou2014a,Robins2013a,Calis2014a}
\citation{Vollmers2013,Jiang2013a,Parameswaran2013,Thomas2014b,Laserson2014,Wang2015,Qi2016,Pogorelyy2018c,Horns2019}
\citation{Logan2011}
\citation{Dash2017,Glanville2017}
\citation{Emerson2017}
\citation{Britanova2016}
\citation{Chu2019}
\citation{Chao2004,Zilman2010,DeBoer:2013p13069,Desponds2016}
\citation{Robins2012a}
\citation{Robinson2008,Robinson2010,Anders2010,Love2014}
\citation{Pogorelyy2018c}
\newlabel{FirstPage}{{}{1}{}{Doc-Start}{}}
\newlabel{FirstPage@cref}{{}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {}Results}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {}Modeling repertoire variation}{1}{section*.2}\protected@file@percent }
\citation{Mora2016e,Gerritsen_thesis,Greef2019}
\citation{Zarnitsyna2013,Heather2017}
\citation{Robinson2010,Love2014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {}Distribution of lymphocyte clone sizes}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {}Noise model for sampling and sequencing}{2}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {}Dynamical model of the immune response}{2}{section*.5}\protected@file@percent }
\newlabel{eq:exp}{{4}{2}{}{equation.0.4}{}}
\newlabel{eq:exp@cref}{{[equation][4][]4}{[1][2][]2}}
\citation{Qi2014,Lythe2016}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  \emph  {Model components}. (A) Clone frequencies are sampled from a prior density of power law form with power $\nu $ and minimum frequency, $f_\textrm  {min}$. (B) Each clone's frequency $f$ determines the count distribution, $P(n|f)$, that governs its mRNA count statistics in the observed sample. We consider 3 forms for $P(n|f)$: Poisson, negative binomial, and a two-step (negative binomial to Poisson) model. The negative binomial and two-step measurement models are parametrized through a mean-variance relationship specifying the power, $\gamma $, and coefficient, $a$, of the over-dispersion of cell count statistics. The mean cell count scales with the number of cells in the sample, $M$, while the mean read count scales with with the number of cells, $m$, and the sampling efficiency, $M/N_{\textrm  {read}}$, with $N_{\textrm  {read}}$ the measured number of molecules in the sample. The parameters of the measurement model are learned on pairs of sequenced repertoire replicates. (C) Differential expression is implemented in the model via a random log fold change, $s$, distributed according to the prior $\rho (s|\theta _\textrm  {exp})$. The prior's parameters, $\theta _\textrm  {exp}$, are learned from the dataset using maximum likelihood. Once learned, the model is used to compute posteriors over $s$ given observed count pairs, which is used to make inferences about specific clones. }}{3}{figure.1}\protected@file@percent }
\newlabel{fig:fullmodel}{{1}{3}{\emph {Model components}. (A) Clone frequencies are sampled from a prior density of power law form with power $\nu $ and minimum frequency, $f_\textrm {min}$. (B) Each clone's frequency $f$ determines the count distribution, $P(n|f)$, that governs its mRNA count statistics in the observed sample. We consider 3 forms for $P(n|f)$: Poisson, negative binomial, and a two-step (negative binomial to Poisson) model. The negative binomial and two-step measurement models are parametrized through a mean-variance relationship specifying the power, $\gamma $, and coefficient, $a$, of the over-dispersion of cell count statistics. The mean cell count scales with the number of cells in the sample, $M$, while the mean read count scales with with the number of cells, $m$, and the sampling efficiency, $M/N_{\textrm {read}}$, with $N_{\textrm {read}}$ the measured number of molecules in the sample. The parameters of the measurement model are learned on pairs of sequenced repertoire replicates. (C) Differential expression is implemented in the model via a random log fold change, $s$, distributed according to the prior $\rho (s|\theta _\textrm {exp})$. The prior's parameters, $\theta _\textrm {exp}$, are learned from the dataset using maximum likelihood. Once learned, the model is used to compute posteriors over $s$ given observed count pairs, which is used to make inferences about specific clones}{figure.1}{}}
\newlabel{fig:fullmodel@cref}{{[figure][1][]1}{[1][2][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Inferring the noise profile from replicate experiments}{3}{section*.6}\protected@file@percent }
\newlabel{eq:null}{{5}{3}{}{equation.0.5}{}}
\newlabel{eq:null@cref}{{[equation][5][]5}{[1][3][]3}}
\newlabel{eq:MLE}{{6}{3}{}{equation.0.6}{}}
\newlabel{eq:MLE@cref}{{[equation][6][]6}{[1][3][]3}}
\newlabel{eq:postnorm}{{7}{3}{}{equation.0.7}{}}
\newlabel{eq:postnorm@cref}{{[equation][7][]7}{[1][3][]3}}
\citation{Jenkins2010}
\citation{Qi2014}
\citation{Lythe2016}
\citation{Mora2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Learning the repertoire dynamics from pairs of time points}{4}{section*.7}\protected@file@percent }
\newlabel{eq:fullexp}{{9}{4}{}{equation.0.9}{}}
\newlabel{eq:fullexp@cref}{{[equation][9][]9}{[1][4][]4}}
\newlabel{eq:MLEexp}{{10}{4}{}{equation.0.10}{}}
\newlabel{eq:MLEexp@cref}{{[equation][10][]10}{[1][4][]4}}
\newlabel{eq:onesidedexp}{{12}{4}{}{equation.0.12}{}}
\newlabel{eq:onesidedexp@cref}{{[equation][12][]12}{[1][4][]4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \emph  {Comparison of measurement models}. Pair count distributions sampled from learned (A) negative binomial and (B) Poisson models, compared to (C) data. (D) shows the log likelihoods, $\ell $ (logarithm of the argument of the argmax in Eq.~\ref  {eq:MLE}) of the Poisson (P) and negative binomial (NB) models relative to that of the two-step model (NBP). (Example dataset: day-0 replicate pair from donor S2.)  }}{5}{figure.2}\protected@file@percent }
\newlabel{fig:nullstats}{{2}{5}{\emph {Comparison of measurement models}. Pair count distributions sampled from learned (A) negative binomial and (B) Poisson models, compared to (C) data. (D) shows the log likelihoods, $\ell $ (logarithm of the argument of the argmax in Eq.~\ref {eq:MLE}) of the Poisson (P) and negative binomial (NB) models relative to that of the two-step model (NBP). (Example dataset: day-0 replicate pair from donor S2.)}{figure.2}{}}
\newlabel{fig:nullstats@cref}{{[figure][2][]2}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  \emph  {Count distributions}. (A) Marginal count distribution, $P(n|\theta _{\textrm  {null}})=\DOTSB \sum@ \slimits@ _{n^{\prime }}P(n,n^{\prime }|\theta _{\textrm  {null}})$, and (B) conditional count distribution, $P(n|n^{\prime },\theta _{\textrm  {null}})=P(n,n^{\prime }|\theta _{\textrm  {null}})/P(n|\theta _{\textrm  {null}})$. Both marginal and conditional distributions are quantitatively predicted by the model. Lines are analytic predictions of the learned model. Dots are estimated frequencies. (Same data as \cref  {fig:nullstats}; two-step noise model). }}{5}{figure.3}\protected@file@percent }
\newlabel{fig:modelfit}{{3}{5}{\emph {Count distributions}. (A) Marginal count distribution, $P(n|\theta _{\textrm {null}})=\sum _{n^{\prime }}P(n,n^{\prime }|\theta _{\textrm {null}})$, and (B) conditional count distribution, $P(n|n^{\prime },\theta _{\textrm {null}})=P(n,n^{\prime }|\theta _{\textrm {null}})/P(n|\theta _{\textrm {null}})$. Both marginal and conditional distributions are quantitatively predicted by the model. Lines are analytic predictions of the learned model. Dots are estimated frequencies. (Same data as \cref {fig:nullstats}; two-step noise model)}{figure.3}{}}
\newlabel{fig:modelfit@cref}{{[figure][3][]3}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  \emph  {Inferred null model parameters}. Inferred values: for (A) the power-law exponent $\nu $ of the clone size distribution; (B) and (C) linear coefficient and exponent of the mean-variance relationship of the noise; (D) effective number of cells; and (E) minimal clonal frequency. Each point is inferred from a pair of replicates for a given donor and time point. Error bars are obtained by inverting the Hessian of the log-likelihood projected onto the hyperplane locally satisfying the normalization constraint. }}{5}{figure.4}\protected@file@percent }
\newlabel{fig:nullparas_timeseries}{{4}{5}{\emph {Inferred null model parameters}. Inferred values: for (A) the power-law exponent $\nu $ of the clone size distribution; (B) and (C) linear coefficient and exponent of the mean-variance relationship of the noise; (D) effective number of cells; and (E) minimal clonal frequency. Each point is inferred from a pair of replicates for a given donor and time point. Error bars are obtained by inverting the Hessian of the log-likelihood projected onto the hyperplane locally satisfying the normalization constraint}{figure.4}{}}
\newlabel{fig:nullparas_timeseries@cref}{{[figure][4][]4}{[1][4][]5}}
\citation{Robinson2010}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \emph  {Diversity estimates.} Shown are diversity estimates obtained from the Hill diversities, $D_\beta $, of the inferred clone frequency distributions for $\beta =0$ (estimated total number of clones, $N$), $\beta =1$ (Shannon entropy) and $\beta =2$ (Simpson index), across donors and days. }}{6}{figure.5}\protected@file@percent }
\newlabel{fig:div_estimates}{{5}{6}{\emph {Diversity estimates.} Shown are diversity estimates obtained from the Hill diversities, $D_\beta $, of the inferred clone frequency distributions for $\beta =0$ (estimated total number of clones, $N$), $\beta =1$ (Shannon entropy) and $\beta =2$ (Simpson index), across donors and days}{figure.5}{}}
\newlabel{fig:div_estimates@cref}{{[figure][5][]5}{[1][4][]6}}
\newlabel{eq:post}{{13}{6}{}{equation.0.13}{}}
\newlabel{eq:post@cref}{{[equation][13][]13}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Inference of the immune response following immunization}{6}{section*.8}\protected@file@percent }
\newlabel{sec:diffexpr}{{}{6}{}{section*.8}{}}
\newlabel{sec:diffexpr@cref}{{}{[1][6][]6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  \emph  {Inference of clonal expansion on synthetic data.}(A) The prior distribution of expansion log fold-changes, $\rho _s(s)$, is parametrized by a mean effect size, $\mathaccentV {bar}016{s}$, describing the expansion of the responding fraction, $\alpha $ of the repertoire (\cref  {eq:onesidedexp}). Expansion is relative to a basal $s_0$ fixed by the normalization constraint. (B) Re-inference of the expansion parameters from synthetic data generated with value $\theta _{\rm  exp}^*=(\mathaccentV {bar}016{s}^*,\alpha ^* )=(1.0,10^{-2})$ (black dot). Maximums of the log-likelihood, $\mathaccentV {hat}05E\theta _{\rm  exp}$, for 50 realizations (gray crosses), along with their average $\mathaccentV {bar}016{\mathaccentV {hat}05E{\theta }}$ (black cross). The log-likelihood for one realization is shown over logarithmically-spaced gray contours decreasing from the maximum. The inverse Fisher information, $\mathcal  {I}^{-1}$, for the same realization is shown as the black-lined ellipse centered at $\mathaccentV {bar}016{\mathaccentV {hat}05E{\theta }}$, which provides a lower bound to the variance of our ML estimate. The gray scale contours increasing to the upper-right denote $Z^\prime /Z-1$, the excess in the used normalization. (C) Posteriors of the learned model, $\rho (s|n,n^{\prime })$ over pairs $(n,n^{\prime })$ for $n^{\prime }=n$, with $n$ varying over a logarithmically-spaced set of counts (left), and for $n^{\prime }$ given by the reverse order of this set (right). The black dot in both plots denotes the contribution of the non-responding component, $\propto \delta (s-s_0)$, to the posterior. (Parameters: $N=10^6$, $\epsilon =10^{-2}$.)  }}{6}{figure.6}\protected@file@percent }
\newlabel{fig:diffexpr_ex1}{{6}{6}{\emph {Inference of clonal expansion on synthetic data.}(A) The prior distribution of expansion log fold-changes, $\rho _s(s)$, is parametrized by a mean effect size, $\bar {s}$, describing the expansion of the responding fraction, $\alpha $ of the repertoire (\cref {eq:onesidedexp}). Expansion is relative to a basal $s_0$ fixed by the normalization constraint. (B) Re-inference of the expansion parameters from synthetic data generated with value $\theta _{\rm exp}^*=(\bar {s}^*,\alpha ^* )=(1.0,10^{-2})$ (black dot). Maximums of the log-likelihood, $\hat \theta _{\rm exp}$, for 50 realizations (gray crosses), along with their average $\bar {\hat {\theta }}$ (black cross). The log-likelihood for one realization is shown over logarithmically-spaced gray contours decreasing from the maximum. The inverse Fisher information, $\mathcal {I}^{-1}$, for the same realization is shown as the black-lined ellipse centered at $\bar {\hat {\theta }}$, which provides a lower bound to the variance of our ML estimate. The gray scale contours increasing to the upper-right denote $Z^\prime /Z-1$, the excess in the used normalization. (C) Posteriors of the learned model, $\rho (s|n,n^{\prime })$ over pairs $(n,n^{\prime })$ for $n^{\prime }=n$, with $n$ varying over a logarithmically-spaced set of counts (left), and for $n^{\prime }$ given by the reverse order of this set (right). The black dot in both plots denotes the contribution of the non-responding component, $\propto \delta (s-s_0)$, to the posterior. (Parameters: $N=10^6$, $\epsilon =10^{-2}$.)}{figure.6}{}}
\newlabel{fig:diffexpr_ex1@cref}{{[figure][6][]6}{[1][6][]6}}
\citation{Boer1993}
\citation{Mayer2019}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  \emph  {Application to yellow fever vaccination data.} Optimal values of $\alpha $ and $\mathaccentV {bar}016{s}$ across all 6 donors and days relative to the day of vaccination (day 0). Inset shows the same data on a logarithmic scale for comparison with \cref  {fig:diffexpr_ex1}b. Comparisons with days other than 0 fall on straight line (dashed line).  }}{7}{figure.7}\protected@file@percent }
\newlabel{fig:diffexpr_ex2}{{7}{7}{\emph {Application to yellow fever vaccination data.} Optimal values of $\alpha $ and $\bar {s}$ across all 6 donors and days relative to the day of vaccination (day 0). Inset shows the same data on a logarithmic scale for comparison with \cref {fig:diffexpr_ex1}b. Comparisons with days other than 0 fall on straight line (dashed line)}{figure.7}{}}
\newlabel{fig:diffexpr_ex2@cref}{{[figure][7][]7}{[1][7][]7}}
\newlabel{eq:symmexp}{{14}{7}{}{equation.0.14}{}}
\newlabel{eq:symmexp@cref}{{[equation][14][]14}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Identifying responding clones}{7}{section*.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  \emph  {Identifying responding clones}. (A) Plot of confidence of expanded response versus average effect size. A significance threshold is placed according to $P_{\textrm  {null}}=0.025$, where $P_{\textrm  {null}}=P(s\leq 0)$. (B) The same threshold for significant expansion in $(n,n^\prime )$-space with identified clones highlighted in red. (C) The optimal values of $\alpha $ and $\mathaccentV {bar}016{s}$ for donor S2 and day-0 day-15 comparison for 3 replicates (square markers). The background heat map is the list overlap (the size of the intersection of the two lists divided by the size of their union) between a reference list obtained at the optimal $\mathaccentV {hat}05E\theta _{\rm  exp}$ (black dot) and lists obtained at non-optimal $\theta _{\rm  exp}$. (D) Mean posterior log fold-change $\delimiter "426830A s\delimiter "526930B _{\rho (s|n,n')}$ as a function of precursor frequency. }}{8}{figure.8}\protected@file@percent }
\newlabel{fig:volcano}{{8}{8}{\emph {Identifying responding clones}. (A) Plot of confidence of expanded response versus average effect size. A significance threshold is placed according to $P_{\textrm {null}}=0.025$, where $P_{\textrm {null}}=P(s\leq 0)$. (B) The same threshold for significant expansion in $(n,n^\prime )$-space with identified clones highlighted in red. (C) The optimal values of $\alpha $ and $\bar {s}$ for donor S2 and day-0 day-15 comparison for 3 replicates (square markers). The background heat map is the list overlap (the size of the intersection of the two lists divided by the size of their union) between a reference list obtained at the optimal $\hat \theta _{\rm exp}$ (black dot) and lists obtained at non-optimal $\theta _{\rm exp}$. (D) Mean posterior log fold-change $\<s\>_{\rho (s|n,n')}$ as a function of precursor frequency}{figure.8}{}}
\newlabel{fig:volcano@cref}{{[figure][8][]8}{[1][7][]8}}
\@writefile{toc}{\contentsline {section}{\numberline {}Discussion}{8}{section*.10}\protected@file@percent }
\citation{Mora2016e,Gerritsen_thesis,Greef2019}
\citation{Qi2014,Lythe2016}
\citation{Robinson2008,Robinson2010,Anders2010,Love2014}
\citation{Ralph2016a}
\citation{Minervina2019}
\citation{Kadoki2017}
\citation{Chu2019}
\citation{Nourmohammad2019}
\@writefile{toc}{\contentsline {section}{\numberline {}Methods}{9}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {}Code}{9}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {}Normalization of the clonal frequencies}{9}{section*.13}\protected@file@percent }
\newlabel{sec:normal}{{}{9}{}{section*.13}{}}
\newlabel{sec:normal@cref}{{}{[1][9][]9}}
\newlabel{eq:joint}{{15}{9}{}{equation.0.15}{}}
\newlabel{eq:joint@cref}{{[equation][15][]15}{[1][9][]9}}
\newlabel{eq:bigZ}{{18}{9}{}{equation.0.18}{}}
\newlabel{eq:bigZ@cref}{{[equation][18][]18}{[1][9][]9}}
\newlabel{eq:largedev}{{19}{10}{}{equation.0.19}{}}
\newlabel{eq:largedev@cref}{{[equation][19][]19}{[1][9][]10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Null model sampling}{10}{section*.14}\protected@file@percent }
\newlabel{sec:null_sampling}{{}{10}{}{section*.14}{}}
\newlabel{sec:null_sampling@cref}{{}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Differential model sampling}{10}{section*.15}\protected@file@percent }
\newlabel{sec:diffexpr_sampling}{{}{10}{}{section*.15}{}}
\newlabel{sec:diffexpr_sampling@cref}{{}{[1][10][]10}}
\citation{Pogorelyy2018c}
\bibcite{Benichou2011}{{1}{}{{}}{{}}}
\bibcite{Georgiou2014a}{{2}{}{{}}{{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Obtaining diversity estimates from the clone frequency density}{11}{section*.16}\protected@file@percent }
\newlabel{sec:infer_div}{{}{11}{}{section*.16}{}}
\newlabel{sec:infer_div@cref}{{}{[1][11][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {}Inferring the differential expression prior}{11}{section*.17}\protected@file@percent }
\newlabel{sec:EM}{{}{11}{}{section*.17}{}}
\newlabel{sec:EM@cref}{{}{[1][11][]11}}
\@writefile{toc}{\contentsline {section}{\numberline {}Acknowledgements}{11}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {}References}{11}{section*.19}\protected@file@percent }
\bibcite{Robins2013a}{{3}{}{{}}{{}}}
\bibcite{Calis2014a}{{4}{}{{}}{{}}}
\bibcite{Vollmers2013}{{5}{}{{}}{{}}}
\bibcite{Jiang2013a}{{6}{}{{}}{{}}}
\bibcite{Parameswaran2013}{{7}{}{{}}{{}}}
\bibcite{Thomas2014b}{{8}{}{{}}{{}}}
\bibcite{Laserson2014}{{9}{}{{}}{{}}}
\bibcite{Wang2015}{{10}{}{{}}{{}}}
\bibcite{Qi2016}{{11}{}{{}}{{}}}
\bibcite{Pogorelyy2018c}{{12}{}{{}}{{}}}
\bibcite{Horns2019}{{13}{}{{}}{{}}}
\bibcite{Logan2011}{{14}{}{{}}{{}}}
\bibcite{Dash2017}{{15}{}{{}}{{}}}
\bibcite{Glanville2017}{{16}{}{{}}{{}}}
\bibcite{Emerson2017}{{17}{}{{}}{{}}}
\bibcite{Britanova2016}{{18}{}{{}}{{}}}
\bibcite{Chu2019}{{19}{}{{}}{{}}}
\bibcite{Chao2004}{{20}{}{{}}{{}}}
\bibcite{Zilman2010}{{21}{}{{}}{{}}}
\bibcite{DeBoer:2013p13069}{{22}{}{{}}{{}}}
\bibcite{Desponds2016}{{23}{}{{}}{{}}}
\bibcite{Robins2012a}{{24}{}{{}}{{}}}
\bibcite{Robinson2008}{{25}{}{{}}{{}}}
\bibcite{Robinson2010}{{26}{}{{}}{{}}}
\bibcite{Anders2010}{{27}{}{{}}{{}}}
\bibcite{Love2014}{{28}{}{{}}{{}}}
\bibcite{Mora2016e}{{29}{}{{}}{{}}}
\bibcite{Gerritsen_thesis}{{30}{}{{}}{{}}}
\bibcite{Greef2019}{{31}{}{{}}{{}}}
\bibcite{Zarnitsyna2013}{{32}{}{{}}{{}}}
\bibcite{Heather2017}{{33}{}{{}}{{}}}
\bibcite{Qi2014}{{34}{}{{}}{{}}}
\bibcite{Lythe2016}{{35}{}{{}}{{}}}
\bibcite{Jenkins2010}{{36}{}{{}}{{}}}
\bibcite{Mora2019}{{37}{}{{}}{{}}}
\bibcite{Boer1993}{{38}{}{{}}{{}}}
\bibcite{Mayer2019}{{39}{}{{}}{{}}}
\bibcite{Ralph2016a}{{40}{}{{}}{{}}}
\bibcite{Minervina2019}{{41}{}{{}}{{}}}
\bibcite{Kadoki2017}{{42}{}{{}}{{}}}
\bibcite{Nourmohammad2019}{{43}{}{{}}{{}}}
\global \chardef \firstnote@num43\relax 
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\bibstyle{pnas}
\newlabel{LastPage}{{}{13}{}{page.13}{}}
\newlabel{LastBibItem}{{43}{13}{}{section*.19}{}}
\newlabel{LastBibItem@cref}{{}{[1][13][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces  \emph  {Reinferring null model parameters}. Shown are the actual and estimated values of the null model parameters used to validate the null model inference procedure over the range exhibited by the data. A 3x3x3x3 grid of points were sampled and results collapsed over each parameter axis. $f_{\rm  min}$ was fixed to satisfy the normalization constraint. }}{13}{figure.1}\protected@file@percent }
\newlabel{fig:SM_reinfer_null}{{S1}{13}{\emph {Reinferring null model parameters}. Shown are the actual and estimated values of the null model parameters used to validate the null model inference procedure over the range exhibited by the data. A 3x3x3x3 grid of points were sampled and results collapsed over each parameter axis. $f_{\rm min}$ was fixed to satisfy the normalization constraint}{figure.1}{}}
\newlabel{fig:SM_reinfer_null@cref}{{[figure][1][]S1}{[1][13][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {S2}{\ignorespaces  \emph  {Dependence of conditional distribution $P(n^\prime =0|n)$ on $n$}. Two-step negative binomial to Poisson model captures tail better than one-step negative binomial model. Poisson model fits poorly. (Example donor S2-day 0 replicate pair.) }}{14}{figure.2}\protected@file@percent }
\newlabel{fig:SM_twostep_better}{{S2}{14}{\emph {Dependence of conditional distribution $P(n^\prime =0|n)$ on $n$}. Two-step negative binomial to Poisson model captures tail better than one-step negative binomial model. Poisson model fits poorly. (Example donor S2-day 0 replicate pair.)}{figure.2}{}}
\newlabel{fig:SM_twostep_better@cref}{{[figure][2][]S2}{[1][13][]14}}
\@writefile{lof}{\contentsline {figure}{\numberline {S3}{\ignorespaces  \emph  {Reinference of differential expression model for human-sized repertoire}. $10^9$ clones were sampled using $N_{\rm  read}=10^6$ and $(\mathaccentV {bar}016{s},\alpha )=(1.0,0.01)$ (cross), and clones with $n=n^\prime =0$ were removed. Note the orders of magnitude higher precision compared to the synthetic mouse repertoire \cref  {fig:diffexpr_ex1}. }}{14}{figure.3}\protected@file@percent }
\newlabel{fig:SM_reinf_diffexpr}{{S3}{14}{\emph {Reinference of differential expression model for human-sized repertoire}. $10^9$ clones were sampled using $N_{\rm read}=10^6$ and $(\bar {s},\alpha )=(1.0,0.01)$ (cross), and clones with $n=n^\prime =0$ were removed. Note the orders of magnitude higher precision compared to the synthetic mouse repertoire \cref {fig:diffexpr_ex1}}{figure.3}{}}
\newlabel{fig:SM_reinf_diffexpr@cref}{{[figure][3][]S3}{[1][13][]14}}
\@writefile{lof}{\contentsline {figure}{\numberline {S4}{\ignorespaces  \emph  {Empirical histograms of naive log-frequency fold-change}. For example data: day-0/day-0 and day-0/day-15 pair comparisons averaged over donors.  }}{15}{figure.4}\protected@file@percent }
\newlabel{fig:SM_snaive_hists}{{S4}{15}{\emph {Empirical histograms of naive log-frequency fold-change}. For example data: day-0/day-0 and day-0/day-15 pair comparisons averaged over donors}{figure.4}{}}
\newlabel{fig:SM_snaive_hists@cref}{{[figure][4][]S4}{[1][13][]15}}
\@writefile{lof}{\contentsline {figure}{\numberline {S5}{\ignorespaces  \emph  {Summary statistics of log-frequency fold-change posterior distributions}. Comparison of the posterior median log-frequency fold-change and the naive estimate, $\qopname  \relax o{log}n^{\prime }/n$ (across clones with $n,n^{\prime }>0$). Each circle is a $(n,n^\prime )$ pair with size proportional to pair count average $(n+n^\prime )/2$ and intensity proportional to the number of observed clones with that pair.  }}{15}{figure.5}\protected@file@percent }
\newlabel{fig:SM_smed_snaive}{{S5}{15}{\emph {Summary statistics of log-frequency fold-change posterior distributions}. Comparison of the posterior median log-frequency fold-change and the naive estimate, $\log n^{\prime }/n$ (across clones with $n,n^{\prime }>0$). Each circle is a $(n,n^\prime )$ pair with size proportional to pair count average $(n+n^\prime )/2$ and intensity proportional to the number of observed clones with that pair}{figure.5}{}}
\newlabel{fig:SM_smed_snaive@cref}{{[figure][5][]S5}{[1][13][]15}}
\@writefile{lof}{\contentsline {figure}{\numberline {S6}{\ignorespaces  \emph  {Competition between $\nu $ and $\mathaccentV {bar}016{s}$ in shaping the posteriors, $\rho (s|0,n^\prime )$}. A) Posteriors for $n^\prime =9$ over a range of $(\mathaccentV {bar}016{s},\alpha )$ pairs spanning the ridge shown in the inset in (B) and \cref  {fig:volcano} along which the growth of $\mathaccentV {bar}016{s}$ leads to $\rho (f)$ overwhelming $\rho _s(s)$ as the dominant explanation for observed expansion. (B) The posterior mean versus $\mathaccentV {bar}016{s}$ for values of $n^\prime =1,\dots  ,9$, with the 5 values of $\mathaccentV {bar}016{s}$ used in (A) shown for $n^\prime =9$. }}{16}{figure.6}\protected@file@percent }
\newlabel{fig:posteriors}{{S6}{16}{\emph {Competition between $\nu $ and $\bar {s}$ in shaping the posteriors, $\rho (s|0,n^\prime )$}. A) Posteriors for $n^\prime =9$ over a range of $(\bar {s},\alpha )$ pairs spanning the ridge shown in the inset in (B) and \cref {fig:volcano} along which the growth of $\bar {s}$ leads to $\rho (f)$ overwhelming $\rho _s(s)$ as the dominant explanation for observed expansion. (B) The posterior mean versus $\bar {s}$ for values of $n^\prime =1,\dots ,9$, with the 5 values of $\bar {s}$ used in (A) shown for $n^\prime =9$}{figure.6}{}}
\newlabel{fig:posteriors@cref}{{[figure][6][]S6}{[1][13][]16}}
